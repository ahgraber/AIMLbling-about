[project]
name = "aiml"
version = "0.0.1"
description = "Utilities for AI/ML experiments"
requires-python = ">=3.10, <3.13"
dependencies = []

[dependency-groups]
dev = ["hatchling>=1.26.3", "ipython>=8.8", "ipywidgets>=8.1.5", "notebook>=7.3.1"]
docs = ["numpydoc>=1.8.0", "sphinx>=8.1.3", "sphinx-rtd-theme>=3.0.2"]
lint = ["ruff>=0.8"]
test = ["coverage>=4.2", "pytest>=8.3.4", "pytest-asyncio>=0.24.0", "pytest-cov>=6.0.0"]
pipelines = ["aiml[test]"]

[project.optional-dependencies]
ds = [
  # ref: https://scientific-python.org/specs/spec-0000/
  "jinja2>=3.1",
  "joblib>=1.4",
  "networkx>3.1",
  "numpy>=1.26",
  "openpyxl>=3.1",
  "pandas>=2",
  "pydantic>=2",
  "python-dateutil>=2.9",
  "python-dotenv>=1.0",
  "pyyaml>=6.0.2",
  "scikit-learn>=1.3",
  "scipy>=1.12",
  "tabulate>=0.9.0",
  "xlrd>=2.0",
]
db = [
  "pyodbc>=5",
  # "redis>=5",
  # "snowflake-connector-python>=3.11",
  # "snowflake-sqlalchemy>=1.6",
  "sqlalchemy>=2",
]
plot = ["cmcrameri>=1.9", "matplotlib>=3.8", "mizani>=0.13", "plotly>=5.24", "plotnine>=0.14", "seaborn>=0.13"]
api = ["fastapi>=0.115.6", "uvicorn>=0.32.1"]
nlp = [
  # "fasttext>=0.9.3",
  "langcodes>=3.5",
  "lingua-language-detector>=2.0",
  "nltk>=3.9",
  "spacy>=3.7",
]
torch = [
  "tensorboard>=2.18",
  "torch>=2",
  "torchaudio>=2.5",
  "torchdata>=0.10",
  "torchmetrics>=1.6",
  "torchtext>=0.18",
  "torchvision>=0.20",
]
transformers = [
  "accelerate>=1.2.0",
  "datasets>=3.2.0",
  "huggingface-hub>=0.23",
  "safetensors>=0.4.5",
  "sentence-transformers>=3.3.1",
  "sentencepiece>=0.2.0",
  "text-generation>=0.7.0",
  "tokenizers>=0.20,<1",
  "transformers>=4.46,<5",
]
langchain = ["langchain>=0.3", "langchain-community>=0.3", "langchain-openai>=0.2", "langchain-text-splitters>=0.3"]
llm = [
  "bm25s>=0.2.5",
  "dspy-ai>=2.5",
  "jiter>=0.8",
  "json-repair>=0.30",
  "openai>=1.57",
  "openapi-core>=0.19",
  "openapi-schema-validator>=0.6",
  "ragas>=0.2",
  "semantic-kernel>=1.17",
  "tenacity>=8.5",
  "tiktoken>=0.8",
]
llamaindex = [
  "llama-index-agent-openai>=0.4.0",
  "llama-index>=0.11,<0.13",
  "llama-index-embeddings-azure-openai>=0.3.0",
  "llama-index-embeddings-openai>=0.3.1",
  "llama-index-llms-azure-inference>=0.3.0",
  "llama-index-llms-azure-openai>=0.3.0",
  "llama-index-llms-huggingface>=0.4.0",
  "llama-index-llms-openai>=0.3.9",
  "llama-index-program-openai>=0.3.1",
  "llama-index-question-gen-openai>=0.3.0",
  "llama-index-readers-file>=0.4.1",
  "llama-index-readers-llama-parse>=0.4.0",
  "llama-index-retrievers-bm25>=0.5.0",
  "llama-index-vector-stores-azureaisearch>=0.3.0",
]

# --- build-system -----------------------------------------------------------
# ref: https://packaging.python.org/en/latest/tutorials/packaging-projects/
# these should match the "setup-requires" packages in `setup.cfg`
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

# ref: https://hatch.pypa.io/1.2/version/#configuration
[tool.hatch.version]
path = "./src/VERSION"
pattern = "^(?P<version>.+?)(\n)"

[tool.hatch.build]
only-include = ["./src/VERSION", "src/aiml", "tests"]
skip-excluded-dirs = true
# sources = ["src"]

[tool.hatch.build.targets.sdist]

[tool.hatch.build.targets.wheel]
packages = ["src/aiml"]
macos-max-compat = true

# --- pytest -----------------------------------------------------------------
# ref: https://docs.pytest.org/en/7.3.x/reference/customize.html
[tool.pytest.ini_options]
addopts = '''
    -ra
    --strict-markers
    --ignore=docs/conf.py
    --ignore=setup.py
    --ignore=ci
    --ignore=.eggs
    --import-mode=importlib
    --tb=short
'''
# --doctest-modules
# --doctest-glob=\*.rst
norecursedirs = [
  ".env",
  ".git",
  ".nox",
  ".pytest_cache",
  ".tox",
  "__pycache__",
  "dist",
  "docs",
  "build",
  "migrations",
  "notebooks",
  "writeup",
]
python_files = ["test_*.py", "*_test.py", "tests.py"]
pythonpath = "src"
testpaths = ["tests"]
# log_cli = true

# --- coverage ---------------------------------------------------------------
[tool.coverage.paths]
source = ["src", "*/site-packages"]

[tool.coverage.run]
branch = true
source = ["src"]

[tool.coverage.report]
show_missing = true
